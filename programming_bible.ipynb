{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Воспроизведение \"King James Programming\" для русского языка, или \"Ветхие алгоритмы\"\n",
    "\n",
    "http://kingjamesprogramming.tumblr.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мотивация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для английского языка есть марковская цепь, натренированная..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 В начале сотворил Бог небо и землю.\n",
      "\n",
      "2 Земля же была безвидна и пуста, и тьма над бездною, и Дух Божий носился над водою.\n",
      "\n",
      "3 И сказал Бог: да будет свет. И стал свет.\n",
      "\n",
      "4 И увидел Бог свет, что он хорош, и отделил Бог свет от тьмы.\n",
      "\n",
      "5 И назвал Бог свет днем, а тьму ночью. И был вечер, и было утро: день один.\n",
      "\n",
      "6 И сказал Бог: да будет твердь посреди воды, и да отделяет она воду от воды. [И стало так.]\n",
      "\n",
      "7 И создал Бог твердь, и отделил воду, которая под твердью, от воды, которая над твердью. И \n",
      "1837153\n"
     ]
    }
   ],
   "source": [
    "# читаем ветхий завет\n",
    "with open('bible.txt', encoding='cp1251') as f:\n",
    "    bible = f.read()\n",
    "    bible = bible[700:] # там было странное\n",
    "    bible = bible[:-365]\n",
    "print(bible[:500])\n",
    "print(len(bible))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "В начале сотворил Бог небо и землю.\n",
      "\n",
      "Земля же была безвидна и пуста, и тьма над бездною, и Дух Божий носился над водою.\n",
      "\n",
      "И сказал Бог: да будет свет. И стал свет.\n",
      "\n",
      "И увидел Бог свет, что он хорош, и отделил Бог свет от тьмы.\n",
      "\n",
      "И назвал Бог свет днем, а тьму ночью. И был вечер, и было утро: день один.\n",
      "\n",
      "И сказал Бог: да будет твердь посреди воды, и да отделяет она воду от воды. [И стало так.]\n",
      "\n",
      "И создал Бог твердь, и отделил воду, которая под твердью, от воды, которая над твердью. И стало так.\n",
      "\n",
      "И \n"
     ]
    }
   ],
   "source": [
    "# чистим ветхий завет\n",
    "import re\n",
    "bible = [re.sub('^[0-9]+ ', '', l) for l in bible.split('\\n\\n')]\n",
    "bible = '\\n\\n'.join(bible).replace('=', '')\n",
    "print(bible[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "охова, то я обнаружил искомую книrу. Если же нет, то я бы продолжил\n",
      "идти вправо, просмаrривая книrу за книгой, пока не нашел бы книrу Шолохова или пока\n",
      "не натолкнулся бы на правую стенку полки (и сделал бы вывод, что на этой полке книrи\n",
      "Шолохова нет). (В rлаве 3, \"Алгоритмы сортировки и поиска\", мы узнаем, как искать кни­\n",
      "ги, если они стоят на полке в определенном порядке.)\n",
      "Вот как мы можем описать задачу поиска в вычислительной терминологии. Будем рас­\n",
      "сматривать полку как массив книr. Крайняя слева книrа находится в позиции 1, следую­\n",
      "щая книrа справа он нее находится в позиции 2, и т.д. Если на полке у нас есть п книr,\n",
      "то крайняя справа книrа находится в позиции п. Мы хотим найти номер позиции любой\n",
      "книrи Шолохова на полке.\n",
      "В качестве обобщенной вычислительной задачи мы получаем массив А (вся книжная\n",
      "полка, на которой мы ищем интересующую нас книrу) сп элементами (отдельными книга­\n",
      "ми), и при этом надо выяснить, присутствует ли в массиве А значение х (книrа Шолохова)\n",
      "Если да, то мы хотим знать индекс i, такой, что A[i] = х (т.е. в i-й позиции на полке стоит\n",
      "книrа Шолохова). Мы также должны иметь возможность каким-то образом сообщить, что\n",
      "массив А не содержит элемент х (на полке нет книr Шолохова). Мы не ограничиваем себя\n",
      "предположением, что х содержится в массиве не более одного раза (возможно, на полке\n",
      "несколько книr Шолохова), так что если элемент х присутствует в массиве А, он может\n",
      "встретиться там несколько раз. Все, что мы хотим от алгоритма поиска, - произвольный\n",
      "индекс, по которому мы найдем элемент х в массиве А. Мы предполагаем, что индексы\n",
      "массива начинаются с l, так что ero элементами являются элементы с А [ l] по А [п].\n",
      "Если мы ищем книrу Шолохова, начиная с левого конца полки и проверяя поочередно\n",
      "все книrи слева направо, такой метод называетсялинейнwм поисклм. В терминах массива\n",
      "в памяти компьютера мы начинаем с начала массива (первого ero элемента), поочередно\n",
      "проверяя все ero элементы (A[l], затем А[2], затем А[З] и так далее до А[п]) и записывая\n",
      "\n",
      "496790\n"
     ]
    }
   ],
   "source": [
    "# Читаем алгоритмы Кормена\n",
    "with open('cormen.txt') as f:\n",
    "    cormen = f.read()\n",
    "    cormen = cormen[5000:]\n",
    "print(cormen[37000:39000])\n",
    "print(len(cormen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ема. (И кроме\n",
      "того, оно обладает таким преимуществом, как краткость.)\n",
      "\n",
      "1.3. Вход в систему\n",
      "Имя пользователя\n",
      "При входе в  систему UNIX мы вводим имя пользователя и  пароль. После этого система отыскивает введенное имя в  файле паролей; обычно это файл /etc/\n",
      "passwd. Файл паролей содержит записи, состоящие из семи полей, разделенных\n",
      "двоеточием: имя пользователя, зашифрованный пароль, числовой идентификатор\n",
      "пользователя (205), числовой идентификатор группы (105), поле комментария,\n",
      "домашний каталог (/home/sar) и командный интерпретатор (/bin/ksh).\n",
      "sar:x:205:105:Stephen Rago:/home/sar:/bin/ksh\n",
      "\n",
      "Все современные системы хранят пароли в отдельном файле. В главе 6 мы рассмотрим эти файлы и некоторые функции доступа к ним.\n",
      "\n",
      "\f",
      "36    Глава 1. Обзор ОС UNIX\n",
      "\n",
      "Командные оболочки\n",
      "Обычно после входа в систему на экран выводится некоторая системная информация, после чего можно вводить команды, предназначенные для командной\n",
      "оболочки. (В некоторых системах после ввода имени пользователя и пароля запускается графический интерфейс, но и в этом случае, как правило, можно получить доступ к командной оболочке, запустив командный интерпретатор в одном\n",
      "из окон.) Командная оболочка — это интерпретатор командной строки, который\n",
      "читает ввод пользователя и выполняет команды. Ввод пользователя обычно считывается из терминала (интерактивная командная оболочка) или из файла (который называется сценарием командной оболочки). В табл. 1.1 перечислены наиболее\n",
      "распространенные командные оболочки.\n",
      "Таблица 1.1. Наибо\n",
      "2137384\n"
     ]
    }
   ],
   "source": [
    "# Читаем юникс\n",
    "with open('unix.txt') as f:\n",
    "    unix = f.read()\n",
    "    unix = unix[82500:]\n",
    "print(unix[:1500])\n",
    "print(len(unix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Порождение. Марковская цепь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Готовая имплементация\n",
    "\n",
    "https://github.com/jsvine/markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3281837"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = bible + cormen + unix[:10 ** 6]\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_m = markovify.Text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "И он распределил их Давид на этого человека и до момента, когда последний процесс в конвейере, и этот каталог и передавала функции lstat она вызывала stat.\n",
      "Ты знаешь необходимость мою, что я люблю тебя и отдадим тебя в плен.\n",
      "Потом пошел Авимелех на гору Селмон, сам и дом царский для себя.\n",
      "Иосиф узнал братьев своих, сыновей царя, со всеми слугами своего господина, и не может сразу следовать за выводом без вызова функций fseek, fsetpos или rewind.\n",
      "Процедура Bu1LD-HUFFМAN-TREE служит примером жадного алгоритма, в котором длина строк превышает 4 байта?\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(text_m.make_sentence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... безудержное веселье! \n",
    "* Мы начнем со строки Х и будем твердо стоять за народ наш и за беззакония наши преданы были мы, цари наши, священники наши и дети мои вокруг меня, когда светильник Его светил над головою моею, и я забросил клюшку и щиток.\n",
    "* Но ведь тоrда тщательно выверенная процедура PARTIТION не будет живущих, ибо, кого Ты поразил, они *еще* преследуют, и страдания уязвленных Тобою умножают.\n",
    "* Шаг 2 выполняется ровно n раз, потому что ячмень выколосился, а лен осеменился; а пшеница и полба не побиты, потому что Господь зовет отрока.\n",
    "* Иосиф узнал братьев своих, сыновей царя, со всеми слугами своего господина, и не может сразу следовать за выводом без вызова функций fseek, fsetpos или rewind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Напишем марковскую цепь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Порождение. LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## План по захвату мира\n",
    "\n",
    "**Проблема**: не все предложения смешные -- большая часть представляет собой либо что-то библиеподобное, либо программистское.\n",
    "\n",
    "**Задача**: автоопределять смешные предложения, то есть отлавливать такие предложения, которые, с болбшой вероятностью, содержат слова и из библии, и из программирования.\n",
    "\n",
    "**Пути решения**:\n",
    "* через tf-idf\n",
    "* классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "testament = sent_tokenize(bible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n\\nВ начале сотворил Бог небо и землю.', 'Земля же была безвидна и пуста, и тьма над бездною, и Дух Божий носился над водою.', 'И сказал Бог: да будет свет.', 'И стал свет.', 'И увидел Бог свет, что он хорош, и отделил Бог свет от тьмы.', 'И назвал Бог свет днем, а тьму ночью.', 'И был вечер, и было утро: день один.', 'И сказал Бог: да будет твердь посреди воды, и да отделяет она воду от воды.', '[И стало так.]', 'И создал Бог твердь, и отделил воду, которая под твердью, от воды, которая над твердью.', 'И стало так.', 'И назвал Бог твердь небом.', '[И увидел Бог, что *это* хорошо.]', 'И был вечер, и было утро: день второй.', 'И сказал Бог: да соберется вода, которая под небом, в одно место, и да явится суша.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13318"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(testament[:15])\n",
    "len(testament)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Кормен (Renee Connen).', 'Предисловие\\nКак компьютеры решают задачи?', 'Как ваш маленький GPS в считанные секунды на\\xad\\nходит самый быстрый пуrь из несметного множества возможных маршруrов?', 'Когда вы\\nпокупаете что-то в Интернете, как обеспечивается защита номера вашей кредитной карты\\nот перехвата злоумышленником?', 'Оrветом на эти и массу других вопросов являются алго\\xad\\nритмы.', 'Я написал эту книгу, чтобы раскрыть вам тайны алгоритмов.', 'Я - соавтор учебника Алгоритмы: построение и анализ.', 'Это замечательная книга\\n(конечно, я небеспристрастен), но местами она представляет собой практически научный\\nтруд.', 'Книга, которую вы держите в своих руках, - совершенно иная.', 'Это даже не учеб\\xad\\nник.', 'Она не погружается в алгоритмы достаточно rnубоко, не охватывает их разнообразие\\nсколь-нибудь широко, не учит методам проектирования компьютерных алгоритмов, и в\\nней даже нет задач и упражнений, которые должен решать читатель!', 'Так что же представ\\xad\\nляет собой эта книга?', 'Это отправная точка для вас, если вы\\n• интересуетесь тем, как компьютеры решают поставленные перед ними задачи;\\n• хотите знать, как оценить качество этих решений;\\n• хотите понимать, как задачи, решаемые компьютерами, и используемые для этого ме\\xad\\nтоды связаны с реальным, некомпьютерным миром;\\n• не очень сильны в математике;\\n• не написали ни одной программы (впрочем, умение программировать нисколько не\\nмешает чтению данной книги, даже наоборот).', 'Некоторые книги о компьютерных алгоритмах концептуальны, с небольшим количе\\xad\\nством технических деталей.', 'Некоторые из них переполнены технически точными описа\\xad\\nниями.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11584"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coding = sent_tokenize(cormen + unix[:10 ** 6])\n",
    "print(coding[:15])\n",
    "len(coding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = testament + coding\n",
    "labels = ['testament'] * len(testament) + ['coding'] * len(coding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>testament</td>\n",
       "      <td>\\n\\nВ начале сотворил Бог небо и землю.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>testament</td>\n",
       "      <td>Земля же была безвидна и пуста, и тьма над без...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>testament</td>\n",
       "      <td>И сказал Бог: да будет свет.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>testament</td>\n",
       "      <td>И стал свет.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>testament</td>\n",
       "      <td>И увидел Бог свет, что он хорош, и отделил Бог...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                          sentences\n",
       "0  testament            \\n\\nВ начале сотворил Бог небо и землю.\n",
       "1  testament  Земля же была безвидна и пуста, и тьма над без...\n",
       "2  testament                       И сказал Бог: да будет свет.\n",
       "3  testament                                       И стал свет.\n",
       "4  testament  И увидел Бог свет, что он хорош, и отделил Бог..."
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'sentences' : sentences, 'labels': labels})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>testament</td>\n",
       "      <td>14\\n\\nИ заметил Иоав, сын Саруи, что сердце ца...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>testament</td>\n",
       "      <td>Живущий на небесах посмеется, Господь поругает...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coding</td>\n",
       "      <td>число ребер т гораздо меньше, чем\\nn2 , реализ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>testament</td>\n",
       "      <td>Говорю ли я, не утоляется скорбь моя; перестаю...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>testament</td>\n",
       "      <td>3\\n\\nСыновья Давида, родившиеся у него в Хевро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>testament</td>\n",
       "      <td>В то же время пришел Иисус и поразил [всех] Ен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>coding</td>\n",
       "      <td>Эти условия определяются не аппаратурой (как, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>testament</td>\n",
       "      <td>Межи мои прошли по прекрасным *местам,* и насл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>coding</td>\n",
       "      <td>Другими словами, при каком значении\\nх величин...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>testament</td>\n",
       "      <td>Наготы сестры отца твоего не открывай, она еди...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                          sentences\n",
       "0  testament  14\\n\\nИ заметил Иоав, сын Саруи, что сердце ца...\n",
       "1  testament  Живущий на небесах посмеется, Господь поругает...\n",
       "2     coding  число ребер т гораздо меньше, чем\\nn2 , реализ...\n",
       "3  testament  Говорю ли я, не утоляется скорбь моя; перестаю...\n",
       "4  testament  3\\n\\nСыновья Давида, родившиеся у него в Хевро...\n",
       "5  testament  В то же время пришел Иисус и поразил [всех] Ен...\n",
       "6     coding  Эти условия определяются не аппаратурой (как, ...\n",
       "7  testament  Межи мои прошли по прекрасным *местам,* и насл...\n",
       "8     coding  Другими словами, при каком значении\\nх величин...\n",
       "9  testament  Наготы сестры отца твоего не открывай, она еди..."
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# перемешаем данные\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['sentences'], df['labels'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  Searched in:\n    - '/home/maryszmary/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  Searched in:\n    - '/home/maryszmary/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-233-c50147e1cf6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstopset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  Searched in:\n    - '/home/maryszmary/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopset = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_preprocessor(text):\n",
    "    text = word_tokenize(text.lower()) # приводим к нижнему регистру и токенизируем\n",
    "    return [w for w in text if w not in stopset + punct] # убираем стоп-слова и пунктуацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "  ...        min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'))])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl = Pipeline(\n",
    "    [('vect', TfidfVectorizer(min_df=5)),\n",
    "    ('tree', DecisionTreeClassifier(random_state=42))]\n",
    ")\n",
    "ppl.fit(X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "  ...ue,\n",
       "        vocabulary=None)), ('tree', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl = Pipeline(\n",
    "    [('vect', TfidfVectorizer(min_df=5)),\n",
    "    ('tree', MultinomialNB())]\n",
    ")\n",
    "ppl.fit(X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     coding       1.00      0.94      0.97      2308\n",
      "  testament       0.95      1.00      0.97      2673\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4981\n",
      "\n",
      "0.9686809877534631\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, ppl.predict(X_test)))\n",
    "print(accuracy_score(y_test, ppl.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44392448, 0.55607552]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl.predict_proba(['Но ведь тоrда тщательно выверенная процедура PARTIТION не будет бога.'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
